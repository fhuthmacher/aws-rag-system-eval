{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be8da33c-eeb6-4d72-a0fc-89f9fb6a19fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# RAG System Evaluation\n",
    "    \n",
    "This notebook is a follow up from the previous notebook in which we explored the overall evaluation approach and a RAG system's overall accuracy.\n",
    "\n",
    "This notebook we will take a closer look at specific RAG metrics and explore how different components and configurations can impact overall accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad47020c-9266-4740-99c2-0d330b90d460",
   "metadata": {},
   "source": [
    "## Solution architecture\n",
    "<img src=\"https://d3q8adh3y5sxpk.cloudfront.net/meetingrecordings/modelevaluation/architecture.png\" alt=\"LLM selection process\" width=\"900\" height=\"550\">\n",
    "\n",
    "From the solution architecture, we will experiment with the below RAG components and evaluate the impact on several metric's relevant for RAG.\n",
    "\n",
    "- 1) Embedding model: amazon.titan-embed-text-v1 vs amazon.titan-e1t-medium \n",
    "- 2) Text Splitter: TokenTextSplitter vs CharacterTextSplitter\n",
    "- 3) Retriever: OpenSearch VectoreStoreRetriever search types “similarity” vs “mmr”\n",
    "- 4) Prompt Template: For each LLM we evaluate two different prompt templates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4514e6",
   "metadata": {},
   "source": [
    "## RAG evaluation metrics\n",
    "\n",
    "This notebook explores the following metrics:\n",
    "\n",
    "Langsmith evaluators: \n",
    "-  a. \"cot_qa\"\n",
    "-  b. \"conciseness\"\n",
    "-  c. \"relevance\"\n",
    "\n",
    "RAGAS metrics: \n",
    "-  a. context_precision\n",
    "-  b. faithfulness\n",
    "-  c. context_recall\n",
    "-  d. answer_relevancy\n",
    "\n",
    "LlamaIndex: \n",
    "-  a. Faithfulness: measure if the response from a query engine matches any source nodes\n",
    "-  b. Relevancy: measure if the response and source nodes match the query\n",
    "-  c. Correctness: assess the relevance and correctness of a generated answer against a reference answer\n",
    "-  d. Semantic Similarity: evaluates the quality of a question answering system via semantic similarity\n",
    "\n",
    "Further information on RAG evaluation metrics can be found here: https://blog.worldline.tech/2024/01/12/metric-driven-rag-development.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6dd86c-115c-49b9-b112-548edf312d33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "%pip install --force-reinstall -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e9545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append your RagasBedrock package path\n",
    "import sys\n",
    "sys.path.append(\"./ragas/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba52a1c8-3b25-4bfa-bbff-5bbbd5de31c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# restart kernel to ensure proper version of libraries is loaded\n",
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b6646c5-8ccf-4e0b-8ea8-0501c379d551",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~rllib3 (/Users/huthmac/.pyenv/versions/3.11.7/envs/rag-eval/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mawscli                    1.32.19\n",
      "boto3                     1.34.36\n",
      "botocore                  1.34.36\n",
      "langchain                 0.1.5\n",
      "langchain-community       0.0.17\n",
      "langchain-core            0.1.18\n",
      "langchain-openai          0.0.5\n",
      "langchainhub              0.1.14\n",
      "mlflow                    2.10.0\n",
      "mypy-boto3-bedrock        1.34.0\n",
      "nest-asyncio              1.6.0\n",
      "nltk                      3.8.1\n",
      "opensearch-py             2.4.2\n",
      "plotly                    5.9.0\n",
      "pypdf                     3.17.4\n",
      "python-dotenv             1.0.0\n",
      "requests-aws4auth         1.2.3\n",
      "sagemaker                 2.207.1\n",
      "tiktoken                  0.5.2\n",
      "xmltodict                 0.13.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~rllib3 (/Users/huthmac/.pyenv/versions/3.11.7/envs/rag-eval/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~rllib3 (/Users/huthmac/.pyenv/versions/3.11.7/envs/rag-eval/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~rllib3 (/Users/huthmac/.pyenv/versions/3.11.7/envs/rag-eval/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip list | grep -E \"awscli|boto3|botocore|langchain|mlflow|plotly|tiktoken|nltk|python-dotenv|xmltodict|requests-aws4auth|pypdf|opensearch-py|sagemaker|nest-asyncio\"\n",
    "# also review requirements.txt for reference if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e938c8c-5e0b-483c-9efd-84c7c9d4e3bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/huthmac/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# load environment variables \n",
    "import boto3\n",
    "import os\n",
    "import botocore\n",
    "from botocore.config import Config\n",
    "import langchain\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.llms import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from typing import Dict\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import sys\n",
    "\n",
    "from langchain.llms import Bedrock\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "# loading environment variables that are stored in local file dev.env\n",
    "load_dotenv(find_dotenv('dev-mlflow.env'),override=True)\n",
    "\n",
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "os.environ['OPENSEARCH_COLLECTION'] = os.getenv('OPENSEARCH_COLLECTION')\n",
    "os.environ['AWS_ACCESS_KEY'] = os.getenv('AWS_ACCESS_KEY')\n",
    "os.environ['AWS_SECRET_TOKEN'] = os.getenv('AWS_SECRET_TOKEN')\n",
    "os.environ['REGION'] = os.getenv('REGION')\n",
    "os.environ['MLFLOW_TRACKING_URI'] = os.getenv('MLFLOW_TRACKING_URI')\n",
    "\n",
    "# Initialize mlflow client\n",
    "\n",
    "mlflow_client = MlflowClient(tracking_uri=os.environ['MLFLOW_TRACKING_URI'])\n",
    "\n",
    "# Initialize Bedrock runtime\n",
    "config = Config(\n",
    "   retries = {\n",
    "      'max_attempts': 8\n",
    "   }\n",
    ")\n",
    "bedrock_runtime = boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd9a12c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RestException",
     "evalue": "RESOURCE_ALREADY_EXISTS: Experiment(name=LLM_accuracy) already exists. Error: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely)\n(pymysql.err.IntegrityError) (1062, \"Duplicate entry 'LLM_accuracy' for key 'experiments.name'\")\n[SQL: INSERT INTO experiments (name, artifact_location, lifecycle_stage, creation_time, last_update_time) VALUES (%(name)s, %(artifact_location)s, %(lifecycle_stage)s, %(creation_time)s, %(last_update_time)s)]\n[parameters: {'name': 'LLM_accuracy', 'artifact_location': '', 'lifecycle_stage': 'active', 'creation_time': 1707334252751, 'last_update_time': 1707334252751}]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestException\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/huthmac/Documents/AWS/00_workspace/RAG_system_evaluation/RAG-System-Eval-DeepDive-mlflow.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/huthmac/Documents/AWS/00_workspace/RAG_system_evaluation/RAG-System-Eval-DeepDive-mlflow.ipynb#X55sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m experiment_tags \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/huthmac/Documents/AWS/00_workspace/RAG_system_evaluation/RAG-System-Eval-DeepDive-mlflow.ipynb#X55sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mproject_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mrag-eval\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/huthmac/Documents/AWS/00_workspace/RAG_system_evaluation/RAG-System-Eval-DeepDive-mlflow.ipynb#X55sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39muse_case\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39minformation extraction\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/huthmac/Documents/AWS/00_workspace/RAG_system_evaluation/RAG-System-Eval-DeepDive-mlflow.ipynb#X55sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmlflow.note.content\u001b[39m\u001b[39m\"\u001b[39m: experiment_description,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/huthmac/Documents/AWS/00_workspace/RAG_system_evaluation/RAG-System-Eval-DeepDive-mlflow.ipynb#X55sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/huthmac/Documents/AWS/00_workspace/RAG_system_evaluation/RAG-System-Eval-DeepDive-mlflow.ipynb#X55sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m experiment_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLLM_accuracy\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/huthmac/Documents/AWS/00_workspace/RAG_system_evaluation/RAG-System-Eval-DeepDive-mlflow.ipynb#X55sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m llm_experiment \u001b[39m=\u001b[39m mlflow_client\u001b[39m.\u001b[39;49mcreate_experiment(name\u001b[39m=\u001b[39;49mexperiment_name, tags\u001b[39m=\u001b[39;49mexperiment_tags)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/huthmac/Documents/AWS/00_workspace/RAG_system_evaluation/RAG-System-Eval-DeepDive-mlflow.ipynb#X55sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Use search_experiments() to search on the project_name tag key\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/huthmac/Documents/AWS/00_workspace/RAG_system_evaluation/RAG-System-Eval-DeepDive-mlflow.ipynb#X55sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m rag_experiment \u001b[39m=\u001b[39m mlflow_client\u001b[39m.\u001b[39msearch_experiments(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/huthmac/Documents/AWS/00_workspace/RAG_system_evaluation/RAG-System-Eval-DeepDive-mlflow.ipynb#X55sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     filter_string\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtags.`project_name` = \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrag-eval\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/huthmac/Documents/AWS/00_workspace/RAG_system_evaluation/RAG-System-Eval-DeepDive-mlflow.ipynb#X55sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/rag-eval/lib/python3.11/site-packages/mlflow/tracking/client.py:570\u001b[0m, in \u001b[0;36mMlflowClient.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_experiment\u001b[39m(\n\u001b[1;32m    523\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    524\u001b[0m     name: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    525\u001b[0m     artifact_location: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    526\u001b[0m     tags: Optional[Dict[\u001b[39mstr\u001b[39m, Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    527\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    528\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \n\u001b[1;32m    530\u001b[0m \u001b[39m    :param name: The experiment name. Must be unique.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[39m        Lifecycle_stage: active\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mcreate_experiment(name, artifact_location, tags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/rag-eval/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py:235\u001b[0m, in \u001b[0;36mTrackingServiceClient.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[39m:param name: The experiment name. Must be unique.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39m:return: Integer ID of the created experiment.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    233\u001b[0m _validate_experiment_artifact_location(artifact_location)\n\u001b[0;32m--> 235\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstore\u001b[39m.\u001b[39;49mcreate_experiment(\n\u001b[1;32m    236\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    237\u001b[0m     artifact_location\u001b[39m=\u001b[39;49martifact_location,\n\u001b[1;32m    238\u001b[0m     tags\u001b[39m=\u001b[39;49m[ExperimentTag(key, value) \u001b[39mfor\u001b[39;49;00m (key, value) \u001b[39min\u001b[39;49;00m tags\u001b[39m.\u001b[39;49mitems()] \u001b[39mif\u001b[39;49;00m tags \u001b[39melse\u001b[39;49;00m [],\n\u001b[1;32m    239\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/rag-eval/lib/python3.11/site-packages/mlflow/store/tracking/rest_store.py:98\u001b[0m, in \u001b[0;36mRestStore.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m     94\u001b[0m tag_protos \u001b[39m=\u001b[39m [tag\u001b[39m.\u001b[39mto_proto() \u001b[39mfor\u001b[39;00m tag \u001b[39min\u001b[39;00m tags] \u001b[39mif\u001b[39;00m tags \u001b[39melse\u001b[39;00m []\n\u001b[1;32m     95\u001b[0m req_body \u001b[39m=\u001b[39m message_to_json(\n\u001b[1;32m     96\u001b[0m     CreateExperiment(name\u001b[39m=\u001b[39mname, artifact_location\u001b[39m=\u001b[39martifact_location, tags\u001b[39m=\u001b[39mtag_protos)\n\u001b[1;32m     97\u001b[0m )\n\u001b[0;32m---> 98\u001b[0m response_proto \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_endpoint(CreateExperiment, req_body)\n\u001b[1;32m     99\u001b[0m \u001b[39mreturn\u001b[39;00m response_proto\u001b[39m.\u001b[39mexperiment_id\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/rag-eval/lib/python3.11/site-packages/mlflow/store/tracking/rest_store.py:59\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body)\u001b[0m\n\u001b[1;32m     57\u001b[0m endpoint, method \u001b[39m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[1;32m     58\u001b[0m response_proto \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39mResponse()\n\u001b[0;32m---> 59\u001b[0m \u001b[39mreturn\u001b[39;00m call_endpoint(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_host_creds(), endpoint, method, json_body, response_proto)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/rag-eval/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:220\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[0m\n\u001b[1;32m    218\u001b[0m     call_kwargs[\u001b[39m\"\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m json_body\n\u001b[1;32m    219\u001b[0m     response \u001b[39m=\u001b[39m http_request(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcall_kwargs)\n\u001b[0;32m--> 220\u001b[0m response \u001b[39m=\u001b[39m verify_rest_response(response, endpoint)\n\u001b[1;32m    221\u001b[0m js_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mtext)\n\u001b[1;32m    222\u001b[0m parse_dict(js_dict\u001b[39m=\u001b[39mjs_dict, message\u001b[39m=\u001b[39mresponse_proto)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/rag-eval/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:152\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m    151\u001b[0m     \u001b[39mif\u001b[39;00m _can_parse_as_json_object(response\u001b[39m.\u001b[39mtext):\n\u001b[0;32m--> 152\u001b[0m         \u001b[39mraise\u001b[39;00m RestException(json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mtext))\n\u001b[1;32m    153\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m         base_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    155\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAPI request to endpoint \u001b[39m\u001b[39m{\u001b[39;00mendpoint\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfailed with error code \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m != 200\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         )\n",
      "\u001b[0;31mRestException\u001b[0m: RESOURCE_ALREADY_EXISTS: Experiment(name=LLM_accuracy) already exists. Error: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely)\n(pymysql.err.IntegrityError) (1062, \"Duplicate entry 'LLM_accuracy' for key 'experiments.name'\")\n[SQL: INSERT INTO experiments (name, artifact_location, lifecycle_stage, creation_time, last_update_time) VALUES (%(name)s, %(artifact_location)s, %(lifecycle_stage)s, %(creation_time)s, %(last_update_time)s)]\n[parameters: {'name': 'LLM_accuracy', 'artifact_location': '', 'lifecycle_stage': 'active', 'creation_time': 1707334252751, 'last_update_time': 1707334252751}]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)"
     ]
    }
   ],
   "source": [
    "# Create a new mlflow experiment\n",
    "\n",
    "experiment_description = (\n",
    "    \"RAG system evaluation project\"\n",
    "    \"This experiment contains the produce models for apples.\"\n",
    ")\n",
    "\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"rag-eval\",\n",
    "    \"use_case\": \"information extraction\",\n",
    "    \"team\": \"aws-ai-ml-analytics\",\n",
    "    \"source\": \"Amazon 10k\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "experiment_name = \"RAG_system_accuracy\"\n",
    "llm_experiment = mlflow_client.create_experiment(name=experiment_name, tags=experiment_tags)\n",
    "\n",
    "# Use search_experiments() to search on the project_name tag key\n",
    "rag_experiment = mlflow_client.search_experiments(\n",
    "    filter_string=\"tags.`project_name` = 'rag-eval'\"\n",
    ")\n",
    "\n",
    "print(rag_experiment[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9f1edb6-2102-48a2-bede-ffabd3caa462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize LLMs (Claude-V2, Cohere, LLama2)\n",
    "\n",
    "## 1a. Initialize Claude-v2\n",
    "llm01_inference_modifier = {\n",
    "    \"max_tokens_to_sample\": 545,\n",
    "    \"temperature\": 0,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "}\n",
    "LLM_01_NAME= \"anthropic.claude-v2\"\n",
    "llm01 = langchain.llms.bedrock.Bedrock( #create a Bedrock llm client\n",
    "    model_id=LLM_01_NAME,\n",
    "    model_kwargs=llm01_inference_modifier\n",
    ")\n",
    "\n",
    "## 1b. Initialize Cohere Command\n",
    "llm02_inference_modifier = { \n",
    "    \"max_tokens\": 545,\n",
    "    \"temperature\": 0,    \n",
    "}\n",
    "LLM_02_NAME= \"cohere.command-text-v14\"\n",
    "llm02 = langchain.llms.bedrock.Bedrock( #create a Bedrock llm client\n",
    "    model_id=LLM_02_NAME,\n",
    "    model_kwargs=llm02_inference_modifier\n",
    ")\n",
    "\n",
    "## 1c. Initialize Llama\n",
    "llm03_inference_modifier = { \n",
    "    \"max_gen_len\": 545,\n",
    "    \"top_p\": 0.9, \n",
    "    \"temperature\": 0,    \n",
    "}\n",
    "LLM_03_NAME= \"meta.llama2-13b-chat-v1\"\n",
    "llm03 = langchain.llms.bedrock.Bedrock( #create a Bedrock llm client\n",
    "    model_id=LLM_03_NAME,\n",
    "    model_kwargs=llm03_inference_modifier\n",
    ")\n",
    "\n",
    "llms = [\n",
    "    llm01,\n",
    "    llm02,\n",
    "    llm03\n",
    "]\n",
    "\n",
    "## 1d. Initialize eval llm\n",
    "inference_modifier = { \n",
    "    \"max_gen_len\": 545,\n",
    "    \"top_p\": 0.9, \n",
    "    \"temperature\": 0,    \n",
    "}\n",
    "LLM_EVAL_NAME= \"meta.llama2-70b-chat-v1\"\n",
    "langchain_eval_llm = langchain.llms.bedrock.Bedrock( #create a Bedrock llm client\n",
    "    model_id=LLM_EVAL_NAME,\n",
    "    model_kwargs=inference_modifier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60611855-58f1-4568-b250-88ed113262e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': \"Who is Amazon's Senior Vice President and General Counsel?\", 'context': 'Available Information\\nOur investor relations website is amazon.com/ir and we encourage investors to use it as a way of easily finding information about us. We promptly make available on this website, free of charge, the reports that we file or furnish with the Securities and Exchange Commission (â\\x80\\x9cSECâ\\x80\\x9d), corporate governance information (including our Code of Business Conduct and Ethics), and select press releases.\\nExecutive Officers and Directors\\nThe following tables set forth certain information regarding our Executive Officers and Directors as of January 25, 2023:\\nInformation About Our Executive Officers\\nName Age Position\\nJeffrey P. Bezos. Mr. Bezos founded Amazon.com in 1994 and has served as Executive Chair since July 2021. He has served as Chair of the Board since 1994 and served as Chief Executive Officer from May 1996 until July 2021, and as President from 1994 until June 1999 and again from October 2000 to July 2021.\\nAndrew R. Jassy. Mr. Jassy has served as President and Chief Executive Officer since July 2021, CEO Amazon Web Services from April 2016 until July 2021, and Senior Vice President, Amazon Web Services, from April 2006 until April 2016.\\nDouglas J. Herrington. Mr. Herrington has served as CEO Worldwide Amazon Stores since July 2022, Senior Vice President, North America Consumer from January 2015 to July 2022, and Senior Vice President, Consumables from May 2014 to December 2014.\\nBrian T. Olsavsky. Mr. Olsavsky has served as Senior Vice President and Chief Financial Officer since June 2015, Vice President, Finance for the Global Consumer Business from December 2011 to June 2015, and numerous financial leadership roles across Amazon with global responsibility since April 2002.\\nShelley L. Reynolds. Ms. Reynolds has served as Vice President, Worldwide Controller, and Principal Accounting Officer since April 2007.\\nAdam N. Selipsky. Mr. Selipsky has served as CEO Amazon Web Services since July 2021, Senior Vice President, Amazon Web Services from May 2021 until July 2021, President and CEO of Tableau Software from September 2016 until May 2021, and Vice President, Marketing, Sales and Support of Amazon Web Services from May 2005 to September 2016.\\nDavid A. Zapolsky. Mr. Zapolsky has served as Senior Vice President, General Counsel, and Secretary since May 2014, Vice President, General Counsel, and Secretary from September 2012 to May 2014, and as Vice President and Associate General Counsel for Litigation and Regulatory matters from April 2002 until September 2012.\\n5\\nJeffrey P. Bezos\\nAndrew R. Jassy\\nDouglas J. Herrington\\nBrian T. Olsavsky\\nShelley L. Reynolds\\nAdam N. Selipsky\\nDavid A. Zapolsky\\n59\\n55\\n56\\n59\\n58\\n56\\n59\\nExecutive Chair\\nPresident and Chief Executive Officer\\nCEO Worldwide Amazon Stores\\nSenior Vice President and Chief Financial Officer\\nVice President, Worldwide Controller, and Principal Accounting Officer\\nCEO Amazon Web Services\\nSenior Vice President, General Counsel, and Secretary', 'output': 'David A. Zapolsky is the Senior Vice President, General Counsel and Secretary', 'page': '5'}\n"
     ]
    }
   ],
   "source": [
    "## 2. download ground truth dataset\n",
    "import xmltodict\n",
    "url = 'https://d3q8adh3y5sxpk.cloudfront.net/rageval/qsdata_20.xml'\n",
    "\n",
    "# Send an HTTP GET request to download the file\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (HTTP status code 200)\n",
    "if response.status_code == 200:        \n",
    "    xml_data = xmltodict.parse(response.text)\n",
    "\n",
    "# Convert the dictionary to a Pandas DataFrame\n",
    "qa_dataset = pd.DataFrame(xml_data['data']['records'])\n",
    "\n",
    "prompts = []\n",
    "for row in qa_dataset.itertuples():\n",
    "    item = {\n",
    "        'prompt': str(row[1]['Question']),\n",
    "        'context': str(row[1]['Context']),\n",
    "        'output': str(row[1]['Answer']['question_answer']),\n",
    "        'page': str(row[1]['Page'])\n",
    "    }\n",
    "    prompts.append(item)\n",
    "\n",
    "# example prompt\n",
    "print(prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae7ee402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenTextSplitter split documents in to 354 chunks.\n",
      "\n",
      "CharacterTextSplitter split documents in to 1364 chunks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Create token_text_splitter and char_text_splitter for evaluation\n",
    "\n",
    "## 3a. download context / Amazon annual report\n",
    "import numpy as np\n",
    "import pypdf\n",
    "from langchain.text_splitter import CharacterTextSplitter, TokenTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "files = [ \"https://d3q8adh3y5sxpk.cloudfront.net/rageval/AMZN-2023-10k.pdf\"]\n",
    "for url in files:\n",
    "    file_path = os.path.join(\"data\", url.rpartition(\"/\")[2])\n",
    "    urlretrieve(url, file_path)\n",
    "    \n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"./data/\")\n",
    "documents = loader.load()\n",
    "\n",
    "token_text_splitter = TokenTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "char_text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "\n",
    "token_text_list = token_text_splitter.split_documents(documents)\n",
    "char_text_list = char_text_splitter.split_documents(documents)\n",
    "    \n",
    "print(\"TokenTextSplitter split documents in to \" + str(len(token_text_list)) + \" chunks.\\n\")\n",
    "print(\"CharacterTextSplitter split documents in to \" + str(len(char_text_list)) + \" chunks.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "196146f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host: lx0j8y3mu9ht6r5xv7za.us-east-1.aoss.amazonaws.com\n",
      "region: us-east-1\n",
      "aospy client:<OpenSearch([{'host': 'lx0j8y3mu9ht6r5xv7za.us-east-1.aoss.amazonaws.com', 'port': 443}])>\n"
     ]
    }
   ],
   "source": [
    "# 4. create vectors and store each document chunk in it's own index in vector database (OpenSearch Serverless)\n",
    "## 4a. connect to OpenSearchServerless\n",
    "import time\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "\n",
    "host = os.environ['OPENSEARCH_COLLECTION']  # serverless collection endpoint, without https://\n",
    "print(f\"host: {host}\")\n",
    "region = os.environ['REGION']  # e.g. us-east-1\n",
    "print(f'region: {region}')\n",
    "\n",
    "\n",
    "service = 'aoss'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, region, service)\n",
    "\n",
    "## 4b. create vectordatabase if it does not exist yet\n",
    "if host == '':\n",
    "    print('creating collection')\n",
    "    vector_store_name = 'rag-eval'\n",
    "    encryption_policy_name = \"rag-eval-ep\"\n",
    "    network_policy_name = \"rag-eval-np\"\n",
    "    access_policy_name = 'rag-eval-ap'\n",
    "    identity = boto3.client('sts').get_caller_identity()['Arn']\n",
    "\n",
    "    aoss_client = boto3.client('opensearchserverless')\n",
    "\n",
    "    security_policy = aoss_client.create_security_policy(\n",
    "        name = encryption_policy_name,\n",
    "        policy = json.dumps(\n",
    "            {\n",
    "                'Rules': [{'Resource': ['collection/' + vector_store_name],\n",
    "                'ResourceType': 'collection'}],\n",
    "                'AWSOwnedKey': True\n",
    "            }),\n",
    "        type = 'encryption'\n",
    "    )\n",
    "\n",
    "    network_policy = aoss_client.create_security_policy(\n",
    "        name = network_policy_name,\n",
    "        policy = json.dumps(\n",
    "            [\n",
    "                {'Rules': [{'Resource': ['collection/' + vector_store_name],\n",
    "                'ResourceType': 'collection'}],\n",
    "                'AllowFromPublic': True}\n",
    "            ]),\n",
    "        type = 'network'\n",
    "    )\n",
    "\n",
    "    collection = aoss_client.create_collection(name=vector_store_name,type='VECTORSEARCH')\n",
    "\n",
    "    while True:\n",
    "        status = aoss_client.list_collections(collectionFilters={'name':vector_store_name})['collectionSummaries'][0]['status']\n",
    "        if status in ('ACTIVE', 'FAILED'): \n",
    "            print(f'new collection {vector_store_name} created')\n",
    "            break\n",
    "        time.sleep(10)\n",
    "\n",
    "    access_policy = aoss_client.create_access_policy(\n",
    "        name = access_policy_name,\n",
    "        policy = json.dumps(\n",
    "            [\n",
    "                {\n",
    "                    'Rules': [\n",
    "                        {\n",
    "                            'Resource': ['collection/' + vector_store_name],\n",
    "                            'Permission': [\n",
    "                                'aoss:CreateCollectionItems',\n",
    "                                'aoss:DeleteCollectionItems',\n",
    "                                'aoss:UpdateCollectionItems',\n",
    "                                'aoss:DescribeCollectionItems'],\n",
    "                            'ResourceType': 'collection'\n",
    "                        },\n",
    "                        {\n",
    "                            'Resource': ['index/' + vector_store_name + '/*'],\n",
    "                            'Permission': [\n",
    "                                'aoss:CreateIndex',\n",
    "                                'aoss:DeleteIndex',\n",
    "                                'aoss:UpdateIndex',\n",
    "                                'aoss:DescribeIndex',\n",
    "                                'aoss:ReadDocument',\n",
    "                                'aoss:WriteDocument'],\n",
    "                            'ResourceType': 'index'\n",
    "                        }],\n",
    "                    'Principal': [identity],\n",
    "                    'Description': 'Easy data policy'}\n",
    "            ]),\n",
    "        type = 'data'\n",
    "    )\n",
    "\n",
    "    host = collection['createCollectionDetail']['id'] + '.' + os.environ.get(\"AWS_DEFAULT_REGION\", None) + '.aoss.amazonaws.com:443'\n",
    "    host = host.split(\":\")[0]\n",
    "    print(f'new aoss host: {host}')\n",
    "\n",
    "aospy_client = OpenSearch(\n",
    "    hosts=[{'host': host, 'port': 443}],\n",
    "    http_auth=auth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    pool_maxsize=20,\n",
    ")\n",
    "print(f'aospy client:{aospy_client}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5292f998-cb7d-408f-8942-f5bba5700a31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5. create and save prompt templates for eval\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "\n",
    "\n",
    "### Claude prompt templates\n",
    "prompt_template_claude_1 = \"\"\"\n",
    "        Human: Given report provided, please read it and analyse the content.\n",
    "        Please answer the following question: {question} basing the answer only on the information from the report\n",
    "        and return it inside <question_answer></question_answer> XML tags.\n",
    "\n",
    "        If a particular bit of information is not present, return an empty string.\n",
    "        Each returned answer should be concise, remove extra information if possible.\n",
    "        The report will be given between <report></report> XML tags.\n",
    "\n",
    "        <report>\n",
    "        {context}\n",
    "        </report>\n",
    "\n",
    "        Return the answer inside <question_answer></question_answer> XML tags.\n",
    "        Assistant:\"\"\"\n",
    "\n",
    "PROMPT_CLAUDE_1 = PromptTemplate(\n",
    "    template=prompt_template_claude_1, input_variables=[\"question\", \"context\"]\n",
    ")\n",
    "\n",
    "prompt_template_claude_2 = \"\"\"\n",
    "        Human: \n",
    "        You are a helpful, respectful, and honest assistant, dedicated to providing valuable and accurate information.\n",
    "\n",
    "        Assistant:\n",
    "        Understood. I will provide information based on the context given, without relying on prior knowledge.\n",
    "\n",
    "        Human:\n",
    "        If you don't see answer in the context just reply \"not available\" in XML tags.\n",
    "\n",
    "        Assistant:\n",
    "        Noted. I will respond with \"not available\" if the information is not available in the context.\n",
    "\n",
    "        Human:\n",
    "        Now read this context and answer the question and return the answer inside <question_answer></question_answer> XML tags. \n",
    "        {context}\n",
    "\n",
    "        Assistant:\n",
    "        Based on the provided context above and information from the retriever source, I will provide the answer in  and return it inside <question_answer></question_answer> XML tags to the below question\n",
    "        {question}\n",
    "        \"\"\"\n",
    "\n",
    "PROMPT_CLAUDE_2 = PromptTemplate(\n",
    "    template=prompt_template_claude_2, input_variables=[\"question\", \"context\"]\n",
    ")\n",
    "\n",
    "### Llama2 prompt templates\n",
    "prompt_template_llama_1 = \"\"\"\n",
    "        [INST] Given report provided, please read it and analyse the content.\n",
    "        Please answer the following question: {question} basing the answer only on the information from the report\n",
    "        and return it inside <question_answer></question_answer> XML tags.\n",
    "\n",
    "        If a particular bit of information is not present, return an empty string.\n",
    "        Each returned answer should be concise, remove extra information if possible.\n",
    "        The report will be given between <report></report> XML tags.\n",
    "\n",
    "        <report>\n",
    "        {context}\n",
    "        </report>\n",
    "\n",
    "        Return the answer inside <question_answer></question_answer> XML tags. [/INST]\n",
    "        \"\"\"\n",
    "PROMPT_LLAMA_1 = PromptTemplate(\n",
    "    template=prompt_template_llama_1, input_variables=[\"question\", \"context\"]\n",
    ")\n",
    "\n",
    "prompt_template_llama_2 = \"\"\"\n",
    "        [INST]\n",
    "        You are a helpful, respectful, and honest assistant, dedicated to providing valuable and accurate information.\n",
    "        [/INST]\n",
    "\n",
    "        Understood. I will provide information based on the context given, without relying on prior knowledge.\n",
    "\n",
    "        [INST]\n",
    "        If you don't see answer in the context just reply \"not available\" in XML tags.\n",
    "        [/INST]\n",
    "\n",
    "        Noted. I will respond with \"not available\" if the information is not available in the context.\n",
    "\n",
    "        [INST]\n",
    "        Now read this context and answer the question and return the answer inside <question_answer></question_answer> XML tags. \n",
    "        {context}\n",
    "        [/INST]\n",
    "\n",
    "        Based on the provided context above and information from the retriever source, I will provide the answer in  and return it inside <question_answer></question_answer> XML tags to the below question\n",
    "        {question}\n",
    "        \"\"\"\n",
    "PROMPT_LLAMA_2 = PromptTemplate(\n",
    "    template=prompt_template_llama_2, input_variables=[\"question\", \"context\"]\n",
    ")\n",
    "\n",
    "\n",
    "### Cohere Command prompt templates\n",
    "prompt_template_command_1 = \"\"\"\n",
    "        Human: Given report provided, please read it and analyse the content.\n",
    "        Please answer the following question: {question} basing the answer only on the information from the report\n",
    "        and return it inside <question_answer></question_answer> XML tags.\n",
    "\n",
    "        If a particular bit of information is not present, return an empty string.\n",
    "        Each returned answer should be concise, remove extra information if possible.\n",
    "        The report will be given between <report></report> XML tags.\n",
    "\n",
    "        <report>\n",
    "        {context}\n",
    "        </report>\n",
    "\n",
    "        Return the answer inside <question_answer></question_answer> XML tags.\n",
    "        Assistant:\"\"\"\n",
    "\n",
    "PROMPT_COMMAND_1 = PromptTemplate(\n",
    "    template=prompt_template_command_1, input_variables=[\"question\", \"context\"]\n",
    ")\n",
    "\n",
    "prompt_template_command_2 = \"\"\"\n",
    "        Human: \n",
    "        You are a helpful, respectful, and honest assistant, dedicated to providing valuable and accurate information.\n",
    "\n",
    "        Assistant:\n",
    "        Understood. I will provide information based on the context given, without relying on prior knowledge.\n",
    "\n",
    "        Human:\n",
    "        If you don't see answer in the context just reply \"not available\" in XML tags.\n",
    "\n",
    "        Assistant:\n",
    "        Noted. I will respond with \"not available\" if the information is not available in the context.\n",
    "\n",
    "        Human:\n",
    "        Now read this context and answer the question and return the answer inside <question_answer></question_answer> XML tags. \n",
    "        {context}\n",
    "\n",
    "        Assistant:\n",
    "        Based on the provided context above and information from the retriever source, I will provide the answer in  and return it inside <question_answer></question_answer> XML tags to the below question\n",
    "        {question}\n",
    "        \"\"\"\n",
    "PROMPT_COMMAND_2 = PromptTemplate(\n",
    "    template=prompt_template_command_2, input_variables=[\"question\", \"context\"]\n",
    ")\n",
    "\n",
    "# generic prompt template for all LLMs\n",
    "generic_rag_template = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "prompttemplates = [\n",
    "    {'template_name': 'generic_rag_template', 'template': generic_rag_template},\n",
    "    {'template_name': 'prompt_template_claude_1', 'template': PROMPT_CLAUDE_1},\n",
    "    {'template_name': 'prompt_template_claude_2', 'template': PROMPT_CLAUDE_2},\n",
    "    {'template_name': 'prompt_template_command_1', 'template': PROMPT_COMMAND_1},\n",
    "    {'template_name': 'prompt_template_command_2', 'template': PROMPT_COMMAND_2},\n",
    "    {'template_name': 'prompt_template_llama_1', 'template': PROMPT_LLAMA_1},\n",
    "    {'template_name': 'prompt_template_llama_2', 'template': PROMPT_LLAMA_2},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88ca290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create helper function to create RAG systems for evaluation\n",
    "import random\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings  \n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "\n",
    "# # LangChain requires AWS4Auth\n",
    "# from requests_aws4auth import AWS4Auth\n",
    "# def get_aws4_auth():\n",
    "#     region = os.environ.get(\"Region\", os.environ[\"REGION\"])\n",
    "#     service = \"aoss\"\n",
    "#     credentials = boto3.Session().get_credentials()\n",
    "#     return AWS4Auth(\n",
    "#         credentials.access_key,\n",
    "#         credentials.secret_key,\n",
    "#         region,\n",
    "#         service,\n",
    "#         session_token=credentials.token,\n",
    "#     )\n",
    "# aws4_auth = get_aws4_auth()\n",
    "\n",
    "\n",
    "def create_rag(rag_system_details):\n",
    "    existing_vector_store = rag_system_details[\"vector_store\"]\n",
    "    llm = rag_system_details[\"llm\"]\n",
    "    aospy_client = rag_system_details[\"aospy_client\"]\n",
    "    index_name = rag_system_details[\"index_name\"]\n",
    "    embedding_model = rag_system_details[\"embedding_model\"]\n",
    "    embedding_model_name = rag_system_details[\"embedding_model_name\"]\n",
    "    splitter_name = rag_system_details[\"splitter_name\"]\n",
    "    text_chunks = rag_system_details[\"text_chunks\"]\n",
    "    index_name = rag_system_details[\"index_name\"]\n",
    "    prompt_template_name = rag_system_details[\"prompt_template_name\"]\n",
    "    prompt_template = rag_system_details[\"prompt_template\"]\n",
    "    chain_type= rag_system_details[\"chain_type\"]\n",
    "    search_type= rag_system_details[\"search_type\"]\n",
    "    retriever_k = rag_system_details[\"retriever_k\"]\n",
    "    score_threshold = rag_system_details[\"score_threshold\"]\n",
    "    fetch_k = rag_system_details[\"fetch_k\"]\n",
    "    lambda_mult = rag_system_details[\"lambda_mult\"]\n",
    "    if existing_vector_store == \"\":\n",
    "        # create index\n",
    "        knn_index = {\n",
    "            \"settings\": {\n",
    "                \"index.knn\": True,\n",
    "                \n",
    "            },\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"vector_field\": {\n",
    "                        \"type\": \"knn_vector\",\n",
    "                        \"dimension\": 1536,\n",
    "                        \"store\": True\n",
    "                    },\n",
    "                    \"text\": {\n",
    "                        \"type\": \"text\",\n",
    "                        \"store\": True\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            aospy_client.indices.delete(index=index_name)\n",
    "            aospy_client.indices.create(index=index_name,body=knn_index,ignore=400)\n",
    "            aospy_client.indices.get(index=index_name)\n",
    "        except:\n",
    "            print(f'Index {index_name} not found. Creating index on OpenSearch.')\n",
    "            aospy_client.indices.create(index=index_name,body=knn_index)\n",
    "            aospy_client.indices.get(index=index_name)\n",
    "\n",
    "        # generate embeddings\n",
    "        full_opensearch_endpoint = 'https://' + os.environ['OPENSEARCH_COLLECTION']\n",
    "\n",
    "        vector_store = OpenSearchVectorSearch.from_documents(\n",
    "                    index_name = index_name,\n",
    "                    documents = text_chunks,\n",
    "                    embedding = embedding_model,\n",
    "                    opensearch_url=full_opensearch_endpoint,\n",
    "                    http_auth=auth,\n",
    "                    use_ssl=True,\n",
    "                    verify_certs=True,\n",
    "                    connection_class=RequestsHttpConnection,\n",
    "                    timeout=60*3,\n",
    "                    bulk_size=1000,\n",
    "                    is_aoss=True\n",
    "                )  \n",
    "    else:\n",
    "        vector_store = existing_vector_store\n",
    "        \n",
    "    random_identifier = random.randrange(100, 1000, 3)\n",
    "    run_name=f'LLM_{llm.model_id}_embeddings{embedding_model_name}_split_{splitter_name}_template_{prompt_template_name}_search_{search_type}_chain_{chain_type}_k_{retriever_k}_{random_identifier}'\n",
    "\n",
    "    search_kwargs = {\n",
    "        \"retriever_k\": retriever_k\n",
    "    }\n",
    "\n",
    "    retriever = vector_store.as_retriever(search_type = search_type, search_kwargs=search_kwargs)\n",
    "\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm,\n",
    "            chain_type=chain_type,\n",
    "            retriever=retriever,\n",
    "            return_source_documents=True,\n",
    "            chain_type_kwargs = {\"prompt\": prompt_template}\n",
    "        )\n",
    "    \n",
    "    return run_name, vector_store, qa_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da7d2b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': \"Who is Amazon's Senior Vice President and General Counsel?\", 'result': ' <question_answer>\\nDavid Zapolsky\\n</question_answer>', 'source_documents': []}\n"
     ]
    }
   ],
   "source": [
    "# test RAG system\n",
    "rag_system_details = {\n",
    "    \"aospy_client\": aospy_client,\n",
    "    \"vector_store\": \"\",\n",
    "    \"llm\": llm01,\n",
    "    \"splitter_name\": \"TokenTextSplitter\",\n",
    "    \"text_chunks\": token_text_list,\n",
    "    \"index_name\": \"rag-eval-tokentextsplitter\",\n",
    "    \"embedding_model_name\": 'bedrock_embeddings',\n",
    "    \"embedding_model\": BedrockEmbeddings(client=bedrock_runtime),\n",
    "    \"prompt_template_name\": \"PROMPT_CLAUDE_1\",\n",
    "    \"prompt_template\": PROMPT_CLAUDE_1,\n",
    "    \"chain_type\": \"stuff\",\n",
    "    \"search_type\": \"similarity\", # alternative: \"mmr\", or \"similarity_score_threshold\" (Default: similarity)\n",
    "    \"retriever_k\": 4, # Amount of documents to return (Default: 4)\n",
    "    \"score_threshold\": 0, # Minimum relevance threshold for similarity_score_threshold\n",
    "    \"fetch_k\": 20, # Amount of documents to pass to MMR algorithm (Default: 20)\n",
    "    \"lambda_mult\": 0.5, # Diversity of results returned by MMR, 1 for minimum diversity and 0 for maximum. (Default: 0.5)\n",
    "         \n",
    "}\n",
    "run_name, vector_store, qa_chain = create_rag(rag_system_details)\n",
    "query = \"Who is Amazon's Senior Vice President and General Counsel?\"\n",
    "result = qa_chain.invoke(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73a13c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from datasets import Dataset\n",
    "import ragas\n",
    "#import tqdm as notebook_tqdm\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    answer_relevancy,\n",
    ")\n",
    "\n",
    "\n",
    "def run_ragas_eval(rag_system_eval_details, rag_system_details):\n",
    "\n",
    "    experiment_name = rag_system_eval_details[\"experiment_name\"]\n",
    "    run_name = rag_system_eval_details[\"run_name\"]\n",
    "    qa_chain = rag_system_eval_details[\"qa_chain\"]\n",
    "    ground_truth = rag_system_eval_details[\"ground_truth\"]\n",
    "\n",
    "    llm_experiment = mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    # Initiate the MLflow run context\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        # list of metrics we're going to use from RAGAS\n",
    "        metrics = [\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "            context_recall,\n",
    "            context_precision,\n",
    "            # harmfulness,\n",
    "        ]\n",
    "\n",
    "        basic_qa_ragas_dataset = []\n",
    "\n",
    "        for item in ground_truth:\n",
    "            result = qa_chain.invoke(item['prompt'])\n",
    "\n",
    "            context_sequence = []\n",
    "            for doc in result[\"source_documents\"]:\n",
    "                context_sequence.append(doc.page_content)\n",
    "\n",
    "            basic_qa_ragas_dataset.append(\n",
    "                    {\"question\" : item['prompt'],\n",
    "                    \"answer\" : result[\"result\"],\n",
    "                    \"contexts\" : context_sequence,\n",
    "                    \"ground_truths\" : [item['output']]\n",
    "                    }\n",
    "                )\n",
    "            basic_qa_ragas_df = pd.DataFrame(basic_qa_ragas_dataset)\n",
    "            basic_qa_ragas = Dataset.from_pandas(basic_qa_ragas_df)\n",
    "\n",
    "        # evaluate\n",
    "        ragas_result = evaluate(basic_qa_ragas, metrics=metrics)\n",
    "        evals_df = ragas_result.to_pandas()\n",
    "        \n",
    "\n",
    "        # Log parameters used for the RAG system\n",
    "        params = {\n",
    "            \"llm_name\": rag_system_details[\"llm\"].model_id,\n",
    "            \"splitter_name\": rag_system_details[\"splitter_name\"],\n",
    "            \"index_name\": rag_system_details[\"index_name\"],\n",
    "            \"embedding_model_name\": rag_system_details[\"embedding_model_name\"],\n",
    "            \"prompt_template_name\": rag_system_details[\"prompt_template_name\"],\n",
    "            \"chain_type\": rag_system_details[\"chain_type\"],\n",
    "            \"search_type\": rag_system_details[\"search_type\"],\n",
    "            \"retriever_k\": rag_system_details[\"retriever_k\"],\n",
    "            \"score_threshold\": rag_system_details[\"score_threshold\"],\n",
    "            \"fetch_k\": rag_system_details[\"fetch_k\"],\n",
    "            \"lambda_mult\": rag_system_details[\"lambda_mult\"]\n",
    "        }\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        print(f'faithfulness mean: {evals_df[\"faithfulness\"].mean()}')\n",
    "        print(f'answer_relevancy mean: {evals_df[\"answer_relevancy\"].mean()}')\n",
    "        print(f'context_recall: {evals_df[\"context_recall\"].mean()}')\n",
    "        print(f'context_precision: {evals_df[\"context_precision\"].mean()}')\n",
    "\n",
    "        mlflow_metrics_results = {\n",
    "            \"faithfulness_mean\": evals_df[\"faithfulness\"].mean(),\n",
    "            \"answer_relevancy_mean\": evals_df[\"answer_relevancy\"].mean(),\n",
    "            \"context_recall_mean\": evals_df[\"context_recall\"].mean(),\n",
    "            \"context_precision_mean\": evals_df[\"context_precision\"].mean(),\n",
    "\n",
    "        }\n",
    "        # Log evaluation metrics that were calculated\n",
    "        mlflow.log_metrics(mlflow_metrics_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3cd04c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValueError('Unknown run type: retriever')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValidationError(model='LLMRun', errors=[{'loc': ('response', 'generations', 0, 0, 'type'), 'msg': \"unexpected value; permitted: 'Generation'\", 'type': 'value_error.const', 'ctx': {'given': 'ChatGeneration', 'permitted': ('Generation',)}}])\n",
      " 50%|█████     | 1/2 [00:55<00:55, 55.28s/it]Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValidationError(model='LLMRun', errors=[{'loc': ('response', 'generations', 0, 0, 'type'), 'msg': \"unexpected value; permitted: 'Generation'\", 'type': 'value_error.const', 'ctx': {'given': 'ChatGeneration', 'permitted': ('Generation',)}}])\n",
      "100%|██████████| 2/2 [01:18<00:00, 39.07s/it]\n",
      "Failed to persist run: {\"detail\":\"Not Found\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValidationError(model='LLMRun', errors=[{'loc': ('response', 'generations', 0, 0, 'type'), 'msg': \"unexpected value; permitted: 'Generation'\", 'type': 'value_error.const', 'ctx': {'given': 'ChatGeneration', 'permitted': ('Generation',)}}])\n",
      " 50%|█████     | 1/2 [00:18<00:18, 18.47s/it]Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValidationError(model='LLMRun', errors=[{'loc': ('response', 'generations', 0, 0, 'type'), 'msg': \"unexpected value; permitted: 'Generation'\", 'type': 'value_error.const', 'ctx': {'given': 'ChatGeneration', 'permitted': ('Generation',)}}])\n",
      "100%|██████████| 2/2 [00:24<00:00, 12.49s/it]\n",
      "Failed to persist run: {\"detail\":\"Not Found\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValidationError(model='LLMRun', errors=[{'loc': ('response', 'generations', 0, 0, 'type'), 'msg': \"unexpected value; permitted: 'Generation'\", 'type': 'value_error.const', 'ctx': {'given': 'ChatGeneration', 'permitted': ('Generation',)}}])\n",
      " 50%|█████     | 1/2 [00:35<00:35, 35.69s/it]Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValidationError(model='LLMRun', errors=[{'loc': ('response', 'generations', 0, 0, 'type'), 'msg': \"unexpected value; permitted: 'Generation'\", 'type': 'value_error.const', 'ctx': {'given': 'ChatGeneration', 'permitted': ('Generation',)}}])\n",
      "100%|██████████| 2/2 [00:49<00:00, 24.71s/it]\n",
      "Failed to persist run: {\"detail\":\"Not Found\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValidationError(model='LLMRun', errors=[{'loc': ('response', 'generations', 0, 0, 'type'), 'msg': \"unexpected value; permitted: 'Generation'\", 'type': 'value_error.const', 'ctx': {'given': 'ChatGeneration', 'permitted': ('Generation',)}}])\n",
      " 50%|█████     | 1/2 [00:33<00:33, 33.99s/it]Failed to load rag-eval-run-2 session, using empty session: 1 validation error for TracerSessionV1\n",
      "id\n",
      "  value is not a valid integer (type=type_error.integer)\n",
      "Error in LangChainTracerV1.on_chain_end callback: ValidationError(model='LLMRun', errors=[{'loc': ('response', 'generations', 0, 0, 'type'), 'msg': \"unexpected value; permitted: 'Generation'\", 'type': 'value_error.const', 'ctx': {'given': 'ChatGeneration', 'permitted': ('Generation',)}}])\n",
      "100%|██████████| 2/2 [00:44<00:00, 22.25s/it]\n",
      "Failed to persist run: {\"detail\":\"Not Found\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness mean: 0.8616780045351474\n",
      "answer_relevancy mean: 0.4933361895826723\n",
      "context_recall: 0.15294117647058825\n",
      "context_precision: 0.02869710494905517\n"
     ]
    }
   ],
   "source": [
    "rag_system_eval_details = {\n",
    "    \"experiment_name\": experiment_name,\n",
    "    \"run_name\": run_name,\n",
    "    \"qa_chain\": qa_chain,\n",
    "    \"ground_truth\": prompts\n",
    "}\n",
    "run_ragas_eval(rag_system_eval_details, rag_system_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "0ea56a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column names: Index(['query', 'llm', 'output', 'trainingoutput', 'context',\n",
      "       'trainingcontext', 'evaluationmetric', 'score', 'feedback'],\n",
      "      dtype='object')\n",
      "no of rows: query               63\n",
      "llm                 63\n",
      "output              63\n",
      "trainingoutput      63\n",
      "context             63\n",
      "trainingcontext     60\n",
      "evaluationmetric     0\n",
      "score                0\n",
      "feedback             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# LLAMA_INDEX EVAL\n",
    "\n",
    "## use results from LLMInformationExtraction.ipynb\n",
    "### query,llm,output,trainingoutput,context,trainingcontext,evaluationmetric,score,feedback\n",
    "predictions_df = pd.read_csv('eval_run_predictions.csv')\n",
    "print(f'column names: {predictions_df.columns}')\n",
    "print(f'no of rows: {predictions_df.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "5d363ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run evaluation directly with llama_index on an existing dataframe\n",
    "## Faithfulness: measure if the response from a query engine matches any source nodes\n",
    "## Relevancy: measure if the response and source nodes match the query\n",
    "## Correctness: assess the relevance and correctness of a generated answer against a reference answer\n",
    "## Semantic Similarity: evaluates the quality of a question answering system via semantic similarity\n",
    "\n",
    "from llama_index.llms import Bedrock\n",
    "from llama_index.embeddings import BedrockEmbedding\n",
    "from llama_index import (\n",
    "    ServiceContext\n",
    ")\n",
    "\n",
    "from llama_index.evaluation import (\n",
    "    FaithfulnessEvaluator,\n",
    "    RelevancyEvaluator,\n",
    "    CorrectnessEvaluator,\n",
    "    SemanticSimilarityEvaluator\n",
    ")\n",
    "from llama_index.embeddings import SimilarityMode\n",
    "from llama_index import Document\n",
    "\n",
    "\n",
    "model_kwargs_claude = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_k\": 10,\n",
    "    \"max_tokens_to_sample\": 512\n",
    "}\n",
    "\n",
    "#LLM_EVAL_NAME= \"meta.llama2-70b-chat-v1\"\n",
    "eval_llm = Bedrock(model=\"anthropic.claude-v2\",\n",
    "              #context_size=512,\n",
    "              temperature=0,\n",
    "              additional_kwargs={'max_tokens_to_sample': 512,'top_k': 10})\n",
    "\n",
    "embed_model = BedrockEmbedding().from_credentials(\n",
    "    model_name='amazon.titan-embed-g1-text-02'\n",
    ")\n",
    "\n",
    "service_context_eval = ServiceContext.from_defaults(\n",
    "    llm=eval_llm, \n",
    "    embed_model=embed_model, \n",
    ")\n",
    "\n",
    "faithfulness_evaluator = FaithfulnessEvaluator(service_context=service_context_eval)\n",
    "relevancy_evaluator = RelevancyEvaluator(service_context=service_context_eval)\n",
    "similarity_threshold = 0.8\n",
    "semantic_evaluator = SemanticSimilarityEvaluator(service_context=service_context_eval,\n",
    "                                                 similarity_mode=SimilarityMode.DEFAULT,\n",
    "                                                 similarity_threshold=similarity_threshold) # 0.8 default\n",
    "correctness_evaluator = CorrectnessEvaluator(service_context=service_context_eval) # encountered parsing errors with this class\n",
    "\n",
    "def run_evals(qa_df):\n",
    "    results_list = []\n",
    "    for row in qa_df.itertuples(index=False):\n",
    "        question = row.query\n",
    "        reference_answer = row.trainingoutput\n",
    "        generated_answer = row.output\n",
    "        retrieved_context = row.context.replace('[]','')\n",
    "        retrieved_context = retrieved_context.split(\"/n\")\n",
    "        #print(f'retrieved context: {retrieved_context}')\n",
    "        #print(f'retrieved context type: {type(retrieved_context)}')\n",
    "\n",
    "        faithfulness = False\n",
    "        faithfulness_feedback  = 'not calculated'\n",
    "        faithfulness_score =  0.0\n",
    "        relevancy = False\n",
    "        relevancy_feedback =  'not calculated'\n",
    "        relevancy_score  =  0.0\n",
    "        correctness = False\n",
    "        correctness_feedback = 'not calculated'\n",
    "        correctness_score = 1.0\n",
    "        \n",
    "        if not(len(retrieved_context) == 0 or retrieved_context[0] == ''):\n",
    "\n",
    "            faithfulness_results = faithfulness_evaluator.evaluate(\n",
    "                query=question,\n",
    "                response=generated_answer,\n",
    "                contexts=retrieved_context\n",
    "                )\n",
    "            \n",
    "            relevancy_results = relevancy_evaluator.evaluate(\n",
    "                query=question,\n",
    "                response=generated_answer,\n",
    "                contexts=retrieved_context\n",
    "                )\n",
    "            faithfulness = faithfulness_results.passing\n",
    "            faithfulness_feedback  = faithfulness_results.feedback\n",
    "            faithfulness_score =  faithfulness_results.score\n",
    "            relevancy = relevancy_results.passing\n",
    "            relevancy_feedback =  relevancy_results.feedback\n",
    "            relevancy_score  =  relevancy_results.score\n",
    "            \n",
    "        semantic_results = semantic_evaluator.evaluate(\n",
    "            response=generated_answer,\n",
    "            reference=reference_answer\n",
    "        )\n",
    "\n",
    "        # correctness_results = correctness_evaluator.evaluate(\n",
    "        #     query=question,\n",
    "        #     response=generated_answer,\n",
    "        #     reference=reference_answer\n",
    "        # )\n",
    "\n",
    "        # correctness= correctness_results.passing\n",
    "        # correctness_feedback= correctness_results.feedback\n",
    "        # correctness_score= correctness_results.score\n",
    "\n",
    "        cur_result_dict = {\n",
    "            \"query\": question,\n",
    "            \"generated_answer\": generated_answer,\n",
    "            \"correctness\": correctness,\n",
    "            \"correctness_feedback\": correctness_feedback,\n",
    "            \"correctness_score\": correctness_score,\n",
    "            \"semantic_similarity\": semantic_results.passing,\n",
    "            \"semantic_similarity_threshold\": similarity_threshold,\n",
    "            \"semantic_similarity_score\": semantic_results.score,\n",
    "            \"faithfulness\": faithfulness,\n",
    "            \"faithfulness_feedback\": faithfulness_feedback,\n",
    "            \"faithfulness_score\": faithfulness_score,\n",
    "            \"relevancy\": relevancy,\n",
    "            \"relevancy_feedback\": relevancy_feedback,\n",
    "            \"relevancy_score\": relevancy_score\n",
    "        }\n",
    "        results_list.append(cur_result_dict)\n",
    "    evals_df = pd.DataFrame(results_list)\n",
    "    return evals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST LLAMA_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "259ee3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "!mkdir -p ./data\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "urls = [\n",
    "    'https://d3q8adh3y5sxpk.cloudfront.net/rageval/AMZN-2023-10k.pdf',\n",
    "]\n",
    "\n",
    "filenames = [\n",
    "    'AMZN-2023-10k.pdf',\n",
    "]\n",
    "\n",
    "data_root = \"./data/\"\n",
    "\n",
    "for idx, url in enumerate(urls):\n",
    "    file_path = data_root + filenames[idx]\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4227672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    SimpleDirectoryReader,\n",
    "    LLMPredictor,\n",
    "    ServiceContext,\n",
    "    get_response_synthesizer,\n",
    "    set_global_service_context\n",
    ")\n",
    "from llama_index.indices.document_summary import DocumentSummaryIndex\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b426d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import Bedrock\n",
    "from llama_index.embeddings import BedrockEmbedding\n",
    "\n",
    "model_kwargs_claude = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_k\": 10,\n",
    "    \"max_tokens_to_sample\": 512\n",
    "}\n",
    "\n",
    "llm = Bedrock(model=\"anthropic.claude-v2\",\n",
    "              #context_size=512,\n",
    "              temperature=0,\n",
    "              additional_kwargs={'max_tokens_to_sample': 512,'top_k': 10})\n",
    "\n",
    "embed_model = BedrockEmbedding().from_credentials(\n",
    "    model_name='amazon.titan-embed-g1-text-02'\n",
    ")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=llm, \n",
    "                                               embed_model=embed_model, \n",
    "                                               chunk_size=512)\n",
    "chunk_overlap = 20\n",
    "chunk_size = 512\n",
    "service_context = ServiceContext.from_defaults(llm=llm, \n",
    "                                               embed_model=embed_model, \n",
    "                                               chunk_size=chunk_size,\n",
    "                                               chunk_overlap=chunk_overlap,\n",
    "                                            )\n",
    "set_global_service_context(service_context)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4fa4d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_fn = lambda filename: {\"file_path\": filename, \"file_name\": filename.replace('data/', \"\").replace('.pdf', \"\")}\n",
    "\n",
    "# automatically sets the metadata of each document according to filename_fn\n",
    "documents = SimpleDirectoryReader(\n",
    "    \"./data\", file_metadata=filename_fn\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b924b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '51', 'file_name': 'AMZN-2023-10k', 'file_path': 'data/AMZN-2023-10k.pdf'}\n"
     ]
    }
   ],
   "source": [
    "#review metadata\n",
    "print(documents[50].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0f8c58c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "from llama_index.vector_stores import (\n",
    "    OpensearchVectorStore,\n",
    "    OpensearchVectorClient,\n",
    ")\n",
    "from llama_index import VectorStoreIndex, StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8bc787db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint: https://lx0j8y3mu9ht6r5xv7za.us-east-1.aoss.amazonaws.com\n",
      "<llama_index.vector_stores.opensearch.OpensearchVectorClient object at 0x28d65c290>\n"
     ]
    }
   ],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "\n",
    "host = os.environ['OPENSEARCH_COLLECTION'] # OpenSearch endpoint, for example: my-test-domain.us-east-1.aoss.amazonaws.com\n",
    "service = 'aoss'\n",
    "region = 'us-east-1'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, region, service)\n",
    "\n",
    "endpoint = 'https://' + os.environ['OPENSEARCH_COLLECTION']\n",
    "print(f'endpoint: {endpoint}')\n",
    "index_name = \"rag-eval-v1\"\n",
    "# OpensearchVectorClient stores text in this field by default\n",
    "text_field = \"content\"\n",
    "# OpensearchVectorClient stores embeddings in this field by default\n",
    "embedding_field = \"embedding\"\n",
    "\n",
    "client = OpensearchVectorClient(\n",
    "    endpoint=endpoint,\n",
    "    index=index_name, \n",
    "    dim=1536, \n",
    "    embedding_field=embedding_field, \n",
    "    text_field=text_field,\n",
    "    http_auth=auth, \n",
    "    use_ssl=True, \n",
    "    verify_certs=True, \n",
    "    connection_class=RequestsHttpConnection, \n",
    "    timeout=10,\n",
    ")\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bde544c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize vector store\n",
    "vector_store = OpensearchVectorStore(client)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "# initialize an index using our sample data and the client we just created\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=documents, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "433ce1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Empty Response'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run query\n",
    "query_engine = index.as_query_engine()\n",
    "res = query_engine.query(\"Who is Amazon's Senior Vice President and General Counsel?\")\n",
    "res.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "54b5b7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Empty Response'"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query with filtering - NOT WORKING ATM\n",
    "from llama_index import Document\n",
    "from llama_index.vector_stores.types import MetadataFilters, ExactMatchFilter, MetadataFilter,FilterOperator\n",
    "import regex as re\n",
    "\n",
    "# Create a query engine that only searches certain documents.\n",
    "metadata_query_engine = index.as_query_engine(\n",
    "    filters=MetadataFilters(\n",
    "        filters=[\n",
    "            ExactMatchFilter(\n",
    "                key=\"term\", value='{\"file_path\": \"data/AMZN-2023-10k.pdf\"}'\n",
    "            )\n",
    "            #ExactMatchFilter(key=\"file_name\", value=\"AMZN-2023-10k\")\n",
    "            \n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "res = metadata_query_engine.query(\n",
    "    \"who is Amazon's Senior Vice President and General Counsel?\"\n",
    ")\n",
    "res.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d7c60cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': \"Who is Amazon's Senior Vice President and General Counsel?\", 'context': 'Available Information\\nOur investor relations website is amazon.com/ir and we encourage investors to use it as a way of easily finding information about us. We promptly make available on this website, free of charge, the reports that we file or furnish with the Securities and Exchange Commission (â\\x80\\x9cSECâ\\x80\\x9d), corporate governance information (including our Code of Business Conduct and Ethics), and select press releases.\\nExecutive Officers and Directors\\nThe following tables set forth certain information regarding our Executive Officers and Directors as of January 25, 2023:\\nInformation About Our Executive Officers\\nName Age Position\\nJeffrey P. Bezos. Mr. Bezos founded Amazon.com in 1994 and has served as Executive Chair since July 2021. He has served as Chair of the Board since 1994 and served as Chief Executive Officer from May 1996 until July 2021, and as President from 1994 until June 1999 and again from October 2000 to July 2021.\\nAndrew R. Jassy. Mr. Jassy has served as President and Chief Executive Officer since July 2021, CEO Amazon Web Services from April 2016 until July 2021, and Senior Vice President, Amazon Web Services, from April 2006 until April 2016.\\nDouglas J. Herrington. Mr. Herrington has served as CEO Worldwide Amazon Stores since July 2022, Senior Vice President, North America Consumer from January 2015 to July 2022, and Senior Vice President, Consumables from May 2014 to December 2014.\\nBrian T. Olsavsky. Mr. Olsavsky has served as Senior Vice President and Chief Financial Officer since June 2015, Vice President, Finance for the Global Consumer Business from December 2011 to June 2015, and numerous financial leadership roles across Amazon with global responsibility since April 2002.\\nShelley L. Reynolds. Ms. Reynolds has served as Vice President, Worldwide Controller, and Principal Accounting Officer since April 2007.\\nAdam N. Selipsky. Mr. Selipsky has served as CEO Amazon Web Services since July 2021, Senior Vice President, Amazon Web Services from May 2021 until July 2021, President and CEO of Tableau Software from September 2016 until May 2021, and Vice President, Marketing, Sales and Support of Amazon Web Services from May 2005 to September 2016.\\nDavid A. Zapolsky. Mr. Zapolsky has served as Senior Vice President, General Counsel, and Secretary since May 2014, Vice President, General Counsel, and Secretary from September 2012 to May 2014, and as Vice President and Associate General Counsel for Litigation and Regulatory matters from April 2002 until September 2012.\\n5\\nJeffrey P. Bezos\\nAndrew R. Jassy\\nDouglas J. Herrington\\nBrian T. Olsavsky\\nShelley L. Reynolds\\nAdam N. Selipsky\\nDavid A. Zapolsky\\n59\\n55\\n56\\n59\\n58\\n56\\n59\\nExecutive Chair\\nPresident and Chief Executive Officer\\nCEO Worldwide Amazon Stores\\nSenior Vice President and Chief Financial Officer\\nVice President, Worldwide Controller, and Principal Accounting Officer\\nCEO Amazon Web Services\\nSenior Vice President, General Counsel, and Secretary', 'output': 'David A. Zapolsky is the Senior Vice President, General Counsel and Secretary', 'page': '5'}\n"
     ]
    }
   ],
   "source": [
    "# use Bedrock Knowledgebase retriever\n",
    "from langchain.retrievers.bedrock import AmazonKnowledgeBasesRetriever\n",
    "\n",
    "kb_id = \"<knowledge_base_id>\"\n",
    "\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\",\n",
    "                              config=bedrock_config)\n",
    "\n",
    "retriever = AmazonKnowledgeBasesRetriever(\n",
    "        knowledge_base_id=kb_id,\n",
    "        retrieval_config={\"vectorSearchConfiguration\": {\"numberOfResults\": 4}},\n",
    "\n",
    "    )\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": claude_prompt}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "rag-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
